---
title: "Subgrouping Analysis - Study B V2"
author: "Joel Martinez"
date: '2022-07-10'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
#loading packages used for processing and analysis
library(gtools)
library(stringi)
library(stringr)
library(plyr)
library(ggplot2)
library(table1)
```

```{r, echo=F}
#read in the data and clean it up

files = Sys.glob('data/batch 1/*.csv')

#Combine and preprocess data
data = do.call(smartbind, lapply(files, function(x){
  #print(x) #to check for when issues come up in certain files
  d = read.csv(x, header = T) #read in the file and pull out data
  d$age = d$demo_2..response[d$part_of_expt == 'demographics']
  d$gender = d$demo_1..response[d$part_of_expt == 'demographics']
  d$race = d$demo_0..response[d$part_of_expt == 'demographics']
  attncheck1 = ifelse(d$attention_check_fatal_correctness[d$part_of_expt == 'attentioncheck_heart'] == 'correct', T, F) #check if attention check was correct
  attncheck2 = ifelse(d$attention_check_sort_correctness[d$part_of_expt == 'attentioncheck_sort'] == 'correct', T, F) #check if diff attention check was also correct
  d$passedattn = all(attncheck1, attncheck2)
  lastopinion = names(sort(table(d$stim_opinion[d$opinion_round == max(d$opinion_round, na.rm = T) & d$stim_deviance == 'nondeviant']), decreasing = T))[1]
  d$predcorrect = lastopinion == d$agreement_prediction[d$part_of_expt == 'prediction'] 
  d
}))
#keep only those who passed both attention checks
failed = data[data$passedattn == F,]
data = data[data$passedattn == T,]
```

# Sample description

```{r, echo=F, warning=F}
print('Attention check')
data.frame(failed = length(unique(failed$SubjID)),
           passed = length(unique(data$SubjID)))

# failed.dems = unique(failed[, c('SubjID', 'age', 'race', 'gender', 'Deviant_threshold'),])
# table1(~age+ race+ gender | Deviant_threshold, failed.dems)

print('Demographics')
dems = unique(data[, c('SubjID', 'age', 'race', 'gender', 'Deviant_threshold'),])
table1(~ age+ race+ gender | Deviant_threshold, dems)
```

# Opinion Learning

```{r, echo=F}
learningtask = data[data$part_of_expt == 'learning_task',]
learningtask$round = sapply(learningtask$dynamicVars_key, function(s) strsplit(s,'--')[[1]][2])
learningtask$round = str_replace(learningtask$round, 'opinion', '')
learningtask$round = factor(learningtask$round, levels = as.character(seq(min(as.numeric(learningtask$round)),max(as.numeric(learningtask$round)))))
learningtask$corr = ifelse(learningtask$response_correctness == 'correct', 1, 0)

learningperformance = ddply(learningtask, .(SubjID, Deviant_threshold, round), summarize, accuracy = mean(corr)*100)
learningperformance.avg = ddply(learningperformance, .(Deviant_threshold, round), summarize, acc = mean(accuracy), n =length(accuracy), ci = qt(0.975,df=n-1)*sd(accuracy)/sqrt(n), l.ci= acc-ci, h.ci = acc+ci)

ggplot(learningperformance.avg, aes(x = round, y = acc, color = as.factor(Deviant_threshold), group = as.factor(Deviant_threshold)))+ 
  geom_ribbon(aes(y = acc, ymax = h.ci, ymin = l.ci), alpha = .2)+
  geom_point()+
  geom_line()+
  theme_bw()+
  facet_grid(~Deviant_threshold)+
  scale_y_continuous(labels = seq(0,100,10), breaks = seq(0,100,10), limits = c(0,100))+
  scale_color_discrete(name = 'Deviation')
```

# Opinion Learning, deviants only

```{r, echo=F}
learningtask = data[data$part_of_expt == 'learning_task' & data$stim_deviance == 'deviant',]
learningtask$round = sapply(learningtask$dynamicVars_key, function(s) strsplit(s,'--')[[1]][2])
learningtask$round = str_replace(learningtask$round, 'opinion', '')
learningtask$round = factor(learningtask$round, levels = as.character(seq(min(as.numeric(learningtask$round)),max(as.numeric(learningtask$round)))))
learningtask$corr = ifelse(learningtask$response_correctness == 'correct', 1, 0)

learningperformance = ddply(learningtask, .(SubjID, Deviant_threshold, round), summarize, accuracy = mean(corr)*100)
learningperformance.avg = ddply(learningperformance, .(Deviant_threshold, round), summarize, acc = mean(accuracy), n =length(accuracy), ci = qt(0.975,df=n-1)*sd(accuracy)/sqrt(n), l.ci= acc-ci, h.ci = acc+ci)

ggplot(learningperformance.avg, aes(x = round, y = acc, color = as.factor(Deviant_threshold), group = as.factor(Deviant_threshold)))+ 
  geom_ribbon(aes(y = acc, ymax = h.ci, ymin = l.ci), alpha = .2)+
  geom_point()+
  geom_line()+
  theme_bw()+
  facet_grid(~Deviant_threshold)+
  scale_y_continuous(labels = seq(0,100,10), breaks = seq(0,100,10), limits = c(0,100))+
  scale_color_discrete(name = 'Deviation')
```


# Opinion Learning, nondeviants only

```{r, echo=F}
learningtask = data[data$part_of_expt == 'learning_task' & data$stim_deviance == 'nondeviant',]
learningtask$round = sapply(learningtask$dynamicVars_key, function(s) strsplit(s,'--')[[1]][2])
learningtask$round = str_replace(learningtask$round, 'opinion', '')
learningtask$round = factor(learningtask$round, levels = as.character(seq(min(as.numeric(learningtask$round)),max(as.numeric(learningtask$round)))))
learningtask$corr = ifelse(learningtask$response_correctness == 'correct', 1, 0)

learningperformance = ddply(learningtask, .(SubjID, Deviant_threshold, round), summarize, accuracy = mean(corr)*100)
learningperformance.avg = ddply(learningperformance, .(Deviant_threshold, round), summarize, acc = mean(accuracy), n =length(accuracy), ci = qt(0.975,df=n-1)*sd(accuracy)/sqrt(n), l.ci= acc-ci, h.ci = acc+ci)

ggplot(learningperformance.avg, aes(x = round, y = acc, color = as.factor(Deviant_threshold), group = as.factor(Deviant_threshold)))+ 
  geom_ribbon(aes(y = acc, ymax = h.ci, ymin = l.ci), alpha = .2)+
  geom_point()+
  geom_line()+
  theme_bw()+
  facet_grid(~Deviant_threshold)+
  scale_y_continuous(labels = seq(0,100,10), breaks = seq(0,100,10), limits = c(0,100))+
  scale_color_discrete(name = 'Deviation')
```

# Average deviant-nondeviant similarity

```{r, echo = F}
similarity = data[data$part_of_expt == 'similarity_rating',]
similarity$devpair = similarity$stim_deviance_num_gend
similarity$devpair = str_remove(similarity$devpair, '[ M]')
similarity$devpair = str_remove(similarity$devpair, '[ F]')
similarity$devpair = str_remove(similarity$devpair, '[1-4]')
similarity$devpair = str_remove(similarity$devpair, '[M]')
similarity$devpair = str_remove(similarity$devpair, '[ M]')
similarity$devpair = str_remove(similarity$devpair, '[F]')
similarity$devpair = str_remove(similarity$devpair, '[1-4]')
similarity$targetpair = ifelse(similarity$devpair == "deviant,nondeviant" | similarity$devpair == "nondeviant,deviant", 'DevNon','NonNon')


simsub = ddply(similarity, .(SubjID, Deviant_threshold, targetpair), summarize, n = length(targetpair), avg = mean(response))
simavg = ddply(simsub, .(Deviant_threshold, targetpair), summarize, n = length(targetpair), avgsim = mean(avg), ci = qt(0.975,df=n-1)*sd(avg)/sqrt(n), l.ci= avgsim-ci, h.ci = avgsim+ci)

ggplot(simsub, aes(x = targetpair, y = avg))+
  geom_violin()+
  geom_point(alpha = .2)+
  facet_grid(.~Deviant_threshold)+
  scale_y_continuous(name= 'Average Similarity', breaks = seq(0,100,10))+
  theme_bw()+
  xlab('')+
  geom_point(data=simavg, aes(y=avgsim, color=targetpair), size = 3, position = position_nudge(x=.25))+
  geom_errorbar(data=simavg, aes(y=avgsim, ymax=h.ci, ymin=l.ci, color=targetpair), width=.2, position = position_nudge(x=.25))
  guides(fill = 'none', color='none')
```


# Correlating average DevNon similarity to NonNon similarity 

each point = participant

```{r}
simsub_wide=tidyr::spread(subset(simsub, select = -n), key = "targetpair", value = 'avg')

ggplot(simsub_wide, aes(x = DevNon, y = NonNon))+
  geom_point(alpha = .5)+
  facet_grid(.~Deviant_threshold)+
  theme_bw()+
  ggpubr::stat_cor(method = "pearson",
                   label.x = 5,
                   label.y = 30,
                   size = 2.3,
                   p.accuracy = .0001)
```

# Prediction Confidence
```{r, echo = F}
predictions = data[data$part_of_expt == 'prediction',]
predictions$confidence = data$response[data$part_of_expt == 'prediction_confidence']

preds.avg = ddply(predictions, .(Deviant_threshold), summarize, n = length(Deviant_threshold), m.conf = mean(confidence), ci = qt(0.975,df=n-1)*sd(confidence)/sqrt(n), l.ci= m.conf-ci, h.ci = m.conf+ci)

ggplot(predictions, aes(x = Deviant_threshold, y = confidence, group = Deviant_threshold))+ 
  geom_violin()+
  geom_point(data = preds.avg, aes(y = m.conf), color = 'red', size = 2)+
  geom_errorbar(data = preds.avg, aes(y = m.conf, ymax=h.ci, ymin=l.ci), color = 'red', width = .1)+
  geom_point(alpha = .2)+
  theme_bw()+
  scale_y_continuous(labels = seq(0,100,10), breaks = seq(0,100,10), limits = c(0,100))+
  scale_x_continuous(labels = seq(0,1,.25), breaks = seq(0,1,.25))
```


# Prediction Confidence, by median split of DevNon Average Similarity

```{r, echo=F}
#first calculate median split within each deviant condition
#Problem: doesn it make more sense to go with lower than median in the 75 and 1 conditions?
simmed = ddply(simsub_wide, .(Deviant_threshold), function(s) {
  s$median = median(s$DevNon)
  s$medsplit = ifelse(s$DevNon >= median(s$DevNon), 'High', "Low")
  s
})

ddply(simmed, .(Deviant_threshold), summarize, median = mean(median))

#fix labels
simmed$label = NA
simmed$label[simmed$Deviant_threshold <= .5 & simmed$medsplit == 'High'] = 'Correct'
simmed$label[simmed$Deviant_threshold <= .5 & simmed$medsplit == 'Low'] = 'Incorrect'
simmed$label[simmed$Deviant_threshold > .5 & simmed$medsplit == 'Low'] = 'Correct'
simmed$label[simmed$Deviant_threshold > .5 & simmed$medsplit == 'High'] = 'Incorrect'

predictions.med= merge(predictions, simmed[, c('SubjID', 'label')])

preds.avg.cor = ddply(predictions.med, .(Deviant_threshold, label), summarize, n = length(Deviant_threshold), m.conf = mean(confidence), ci = qt(0.975,df=n-1)*sd(confidence)/sqrt(n), l.ci= m.conf-ci, h.ci = m.conf+ci)

ggplot(predictions.med, aes(x = Deviant_threshold, y = confidence, group = Deviant_threshold))+ 
  geom_violin()+
  geom_point(data = preds.avg.cor, aes(y = m.conf), color = 'red', size = 2)+
  geom_errorbar(data = preds.avg.cor, aes(y = m.conf, ymax=h.ci, ymin=l.ci), color = 'red', width = .1)+
  geom_point(alpha = .2)+
  theme_bw()+
  scale_y_continuous(labels = seq(0,100,10), breaks = seq(0,100,10), limits = c(0,100))+
  scale_x_continuous(labels = seq(0,1,.25), breaks = seq(0,1,.25))+
  facet_grid(~label)
```


# Prediction confidence correlated with DevNon similarity
```{r}
confsim = merge(simsub_wide, predictions)

ggplot(confsim, aes(x = DevNon, y = confidence))+
  geom_point(alpha = .5)+
  facet_grid(.~Deviant_threshold)+
  theme_bw()+
  ggpubr::stat_cor(method = "pearson",
                   label.x = 5,
                   label.y = 9,
                   size = 2.3,
                   p.accuracy = .0001)
```


# Prediction Confidence, by correctness about last opinion

```{r, echo=F}
table1(~predcorrect, predictions)
table1(~predcorrect | Deviant_threshold, predictions)


preds.avg.cor = ddply(predictions, .(Deviant_threshold, predcorrect), summarize, n = length(Deviant_threshold), m.conf = mean(confidence), ci = qt(0.975,df=n-1)*sd(confidence)/sqrt(n), l.ci= m.conf-ci, h.ci = m.conf+ci)

ggplot(predictions, aes(x = Deviant_threshold, y = confidence, group = Deviant_threshold))+ 
  geom_violin()+
  geom_point(data = preds.avg.cor, aes(y = m.conf), color = 'red', size = 2)+
  geom_errorbar(data = preds.avg.cor, aes(y = m.conf, ymax=h.ci, ymin=l.ci), color = 'red', width = .1)+
  geom_point(alpha = .2)+
  theme_bw()+
  scale_y_continuous(labels = seq(0,100,10), breaks = seq(0,100,10), limits = c(0,100))+
  scale_x_continuous(labels = seq(0,1,.25), breaks = seq(0,1,.25))+
  facet_grid(~predcorrect)+
  ggtitle("Correct about last opinion?")
```

# Order of deviant each round

```{r, echo = F}
devdata = data[data$stim_deviance == 'deviant' & data$part_of_expt == 'learning_task',]

table1(~ as.factor(trial_index) | opinion_round, devdata)
```


#Cluster analysis
```{r, eval = F}
library(JuliaCall)
julia_setup(JULIA_HOME = "/Applications/Julia-1.8.app/Contents/Resources/julia/bin/")
julia_source(file_name = '../clustering/InfiniteSimilarityModel.jl')

runISM = function(X){
  julia_assign('X', X)
  julia_assign('chain', julia_eval('sample(ISM(X), SMC(), 5000);'))
  P = julia_eval('clusterprob(chain)')
  k = julia_eval('numclusters(chain)')
  list(P = P, k = k)
}
```

```{r, eval =F}
#test if the function works as intended
library(Matrix)
clusterMatrix = function(k, obs){
  M = matrix(1, nrow = obs, ncol = obs)
  X = as.matrix(bdiag(rep(list(M), k)))
  X*.99
}
X = clusterMatrix(k=3, obs=8)

results = runISM(X)
results$P
mean(results$k)
```


```{r, eval = F}
#Create containers to record output
subs = unique(data[,c('SubjID', 'Deviant_threshold')])
subs$k = NA
submats = vector('list', length(subs$SubjID))
subprobmats = vector('list', length(subs$SubjID))
#make similarity matrix
for(i in 1:length(subs$SubjID)){
  subdat = similarity[similarity$SubjID == subs$SubjID[i],]
  #need unique names of the stimuli used
  subdat$stim1 = sapply(subdat$stim_names, function(s) strsplit(s, ',')[[1]][1])
  subdat$stim2 = sapply(subdat$stim_names, function(s) strsplit(s, ',')[[1]][2])
  allstim = unique(c(subdat$stim1, subdat$stim2))
  #use them to create matrix size
  mat = matrix(nrow = length(allstim), ncol = length(allstim))
  #name rows and columns by stimuli names so we can fill in
  colnames(mat) = allstim
  row.names(mat) = allstim
  #fill in matrix!
  for(row in 1:nrow(mat)){
    for(col in 1:ncol(mat)){
      if(row == col){ #dont have similarity to self, so give perfect similarity
        mat[row, col] = 100
        next
      }
      rname = row.names(mat)[row]
      cname = colnames(mat)[col]
      #find similarity response for pair
      mat[row, col] = subdat$response[subdat$stim_names == paste0(rname, ',', cname) | subdat$stim_names == paste0(cname, ',', rname)]
    }
  }
  subdat$dev1 = sapply(subdat$stim_deviance_num_gend, function(s) strsplit(s, ',')[[1]][1])
  subdat$dev2 = sapply(subdat$stim_deviance_num_gend, function(s) strsplit(s, ',')[[1]][2])
  devdf = unique(data.frame(stim = c(subdat$stim1, subdat$stim2), dev = c(subdat$dev1, subdat$dev2)))
  devdf$dev = gsub('nondeviant ', '', devdf$dev)
  for(b in 1:nrow(mat)){
    colnames(mat)[b] = devdf$dev[devdf$stim == colnames(mat)[b]]
    row.names(mat)[b] = devdf$dev[devdf$stim == row.names(mat)[b]]
  }
  #order so deviant always in upper left corner
  mat = mat[order(colnames(mat), decreasing = F), order(colnames(mat), decreasing = F)]
  
  #normalize for Turing function 
  mat = mat/100
  
  #save similarity matrix just in case
  submats[[i]] = mat
  
  #cluster model
  results = runISM(mat)
  
  #Save number of clusters
  subs$k[i] = mean(results$k)
  
  #estimate probability matrix between agents
  P = results$P
  colnames(P) = colnames(mat)
  row.names(P) = row.names(mat)
  
  #save probability matrix
  subprobmats[[i]] = P
  svMisc::progress(i, length(subs$SubjID))
  
  # par(mfrow=c(2,2))
  # corrplot::corrplot(mat)
  # corrplot::corrplot(P)
  # corrplot::corrplot(mat, order = 'hclust')
  # corrplot::corrplot(P, order = 'hclust')
}

# save the probability matrices & data frame so only have to run once (until something needs changing)
saveRDS(submats, file = "subsimmats.rds")
saveRDS(subprobmats, file = "subprobmats.rds")
saveRDS(subs, file = "subs-kestimates.rds")
```


```{r}
subprobmats = readRDS('subprobmats.rds')
subs = readRDS('subs-kestimates.rds')

kplot = ddply(subs, .(Deviant_threshold), summarize, n= length(Deviant_threshold), avg = mean(k), ci = qt(.975, n-1)*sd(k)/sqrt(n), low.ci = avg - ci, hi.ci = avg + ci)

ggplot(subs, aes(x = as.factor(Deviant_threshold), y = k, group = Deviant_threshold))+ 
  geom_violin(draw_quantiles = c(0.25, 0.75), linetype = "dashed") +
  geom_violin(fill="transparent",draw_quantiles = 0.5) +
  geom_point(alpha = .2)+
  theme_bw()+
  scale_y_continuous(name = 'k (number of clusters)')+
  geom_point(data=kplot, aes(y = avg), color = 'red')+
  geom_errorbar(data=kplot, aes(y = avg, ymax = hi.ci, ymin = low.ci), color = 'red', width = .2)+
  scale_x_discrete(name = 'Deviance')+
  ggtitle('Infinite Similarity Model results')
ggsave('ism.eps', height = 5, width = 5)
```